<!DOCTYPE html>
<html lang="en" data-theme=""><head>
    <title> Tobias Larysch | Titanic: Machine Learning from Disaster - 2021 Update: Streamlit </title>

    
    <meta charset="utf-8"><meta name="generator" content="Hugo 0.74.3" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
    <meta name="description" content="Economist and Data Enthusiast">
    
    <link rel="stylesheet"
          href="../../css/style.min.9a6700e4461b50dccdddfc4f81dc65d77e7fca22c35665e398a0c36568db59c7.css"
          integrity="sha256-mmcA5EYbUNzN3fxPgdxl135/yiLDVmXjmKDDZWjbWcc="
          crossorigin="anonymous"
          type="text/css">
    
    <link rel="stylesheet"
        href="../../css/markupHighlight.min.9755453ffb7bc4cd220f86ebb5922107b49f193cc62fc17e9785d27b33a8bf5b.css"
        integrity="sha256-l1VFP/t7xM0iD4brtZIhB7SfGTzGL8F&#43;l4XSezOov1s="
        crossorigin="anonymous"
        type="text/css">
    
        
        
        <link rel="stylesheet"
        href="../../css/custom4.min.e9be054c66185a392f19a6b0cee73ff9da6c394169a56c638a561cad15758611.css"
        integrity="sha256-6b4FTGYYWjkvGaawzuc/&#43;dpsOUFppWxjilYcrRV1hhE="
        crossorigin="anonymous"
        media="screen" />
    
        
        
        <link rel="stylesheet"
        href="../../css/friend.min.d0809843e4028aaa20decda8dda26d1a3bae5e47e87311da5a10b607f015390a.css"
        integrity="sha256-0ICYQ&#43;QCiqog3s2o3aJtGjuuXkfocxHaWhC2B/AVOQo="
        crossorigin="anonymous"
        media="screen" />
    
    <link rel="stylesheet" 
    href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css" 
    integrity="sha512-+4zCK9k+qNFUR5X+cKL9EIR+ZOhtIloNl9GIKS57V1MyNsYpYcUrUeQc9vNfzsWfV28IaLL3i96P9sdNyeRssA==" 
    crossorigin="anonymous" />

    
    <link rel="shortcut icon" href="../../favicons/favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon" sizes="180x180" href="../../favicons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../../favicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../../favicons/favicon-16x16.png">

    <link rel="canonical" href="../../post/titanic/">

    
    
    
    
    <script type="text/javascript"
            src="../../js/anatole-header.min.d8599ee07b7d3f11bafbac30657ccc591e8d7fd36a9f580cd4c09e24e0e4a971.js"
            integrity="sha256-2Fme4Ht9PxG6&#43;6wwZXzMWR6Nf9Nqn1gM1MCeJODkqXE="
            crossorigin="anonymous"></script>


    <script type="text/javascript"
            src="../../js/custom.min.adead2e63eefe548b5ce0aa68303df62a2e2e975242f58d58c080fb3a61e11d7.js"
            integrity="sha256-rerS5j7v5Ui1zgqmgwPfYqLi6XUkL1jVjAgPs6YeEdc="
            crossorigin="anonymous"></script>
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Titanic: Machine Learning from Disaster - 2021 Update: Streamlit"/>
<meta name="twitter:description" content="This blogpost contains code for the Kaggle Titanic challenge. It is a well-known beginner challenge and its goal is to build a binary classification model to predict if passengers would have survived the Titanic disaster or not. The focus of this blogpost is on Exploratory Data Analysis and some Feature Engineering. Later on, I built and deployed a small ML app using Streamlit and Streamlit Sharing."/>


    
	<script async src="https://cdn.panelbear.com/analytics.js?site=cIJFGgu2o5"></script>
	<script>
    	window.panelbear = window.panelbear || function() { (window.panelbear.q = window.panelbear.q || []).push(arguments); };
    	panelbear('config', { site: 'cIJFGgu2o5', debug: true });
	</script>


    

    
    <script>
    
    window.onload = function(){
    document
        .getElementById("Linkedin")
        .addEventListener("click", function (e) {
        e.preventDefault();

        
        panelbear("track", "LinkedIn");
        
        
        window.open(this.href, "_tab");
        
    });
    
    
    document
        .getElementById("GitHub")
        .addEventListener("click", function (e) {
        e.preventDefault();

        
        panelbear("track", "GitHub");
        
        
        window.open(this.href, "_blank");
        
    });
    


    

    
    document
        .getElementById("e-mail")
        .addEventListener("click", function (e) {
        e.preventDefault();

        
        panelbear("track", "Mail");
        
        
        window.open(this.href, "_blank");
        
    });
    
    
    document
        .getElementById("Xing")
        .addEventListener("click", function (e) {
        e.preventDefault();

        
        panelbear("track", "Xing");
        
        
        window.open(this.href, "_blank");
        
    });
    }
    </script>






</head>
<body><div class="sidebar . ">
    <div class="logo-title">
        <div class="title">
            <img src="../../images/foto_cropped_small.jpg" alt="profile picture">
            <h3 title=""><a href="../../">Tobias Larysch - Portfolio</a></h3>
            <div class="description">
                <p>Economist and Data Enthusiast</p>
            </div>
        </div>
    </div>
    <ul class="social-links">
        
            <li>
                <a href="https://www.linkedin.com/in/tobias-larysch-97981519b/" rel="me" aria-label="Linkedin" id="Linkedin">
                    <i class="fab fa-linkedin fa-2x" aria-hidden="true"></i>
                </a>
            </li>
        
            <li>
                <a href="https://github.com/tlary" rel="me" aria-label="GitHub" id="GitHub">
                    <i class="fab fa-github fa-2x" aria-hidden="true"></i>
                </a>
            </li>
        
            <li>
                <a href="mailto:tobias-larysch@gmx.net" rel="me" aria-label="e-mail" id="e-mail">
                    <i class="fas fa-envelope fa-2x" aria-hidden="true"></i>
                </a>
            </li>
        
            <li>
                <a href="https://www.xing.com/profile/Tobias_Larysch/cv" rel="me" aria-label="Xing" id="Xing">
                    <i class="fab fa-xing fa-2x" aria-hidden="true"></i>
                </a>
            </li>
        
    </ul>
    <div class="footer">
        <div class="by_farbox">&copy; Tobias Larysch  2021 </div>
    </div>
</div>
<div class="main">
    <div class="page-top  . ">
    <a role="button" class="navbar-burger" data-target="navMenu" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
    </a>
    <ul class="nav" id="navMenu">
        
        
            
            <li><a 
                   href="../../"
                        
                   title="">Projects </a></li>
        
            
            <li><a 
                   href="../../publications/"
                        
                   title="">Publications</a></li>
        
        
        
    </ul>
</div>

    <div class="autopagerize_page_element">
        <div class="content">

    <div class="post  . ">
    	
    	
    		<nav id="TableOfContents">
  <ul>
    <li><a href="#1-exploratory-data-analysis-eda">1. Exploratory Data Analysis (EDA)</a>
      <ul>
        <li><a href="#11-numerical-features">1.1 Numerical Features</a></li>
        <li><a href="#12-categorical-features">1.2 Categorical Features</a></li>
      </ul>
    </li>
    <li><a href="#2-data-preparation--feature-engineering">2. Data Preparation &amp; Feature Engineering</a>
      <ul>
        <li><a href="#21-feature-engineering">2.1 Feature Engineering</a></li>
        <li><a href="#22-missing-values">2.2 Missing Values</a></li>
        <li><a href="#23-dummy-variables">2.3 Dummy variables</a></li>
      </ul>
    </li>
    <li><a href="#3-building-the-predictive-models">3. Building the Predictive Models</a>
      <ul>
        <li><a href="#31-random-forest">3.1 Random Forest</a></li>
        <li><a href="#32-xgboost">3.2 XGBoost</a></li>
        <li><a href="#33-comparison-of-kaggle-results">3.3 Comparison of Kaggle results</a></li>
      </ul>
    </li>
    <li><a href="#4-2021-update-building-a-ml-app-using-streamlit">4. 2021 Update: Building a ML app using Streamlit</a>
      <ul>
        <li><a href="#41-data-preparation">4.1 Data Preparation</a></li>
        <li><a href="#42-building-the-toy-model">4.2 Building the Toy Model</a></li>
        <li><a href="#43-building-the-web-app">4.3 Building the Web App</a></li>
      </ul>
    </li>
  </ul>
</nav>
        
    	
        <div class="post-content">
            
            <div class="post-title">
                <h2>Titanic: Machine Learning from Disaster - 2021 Update: Streamlit</h3>
                
                    <div class="info">
                        <em class="fas fa-calendar-day"></em>
                        <span class="date"> 
                                                Fri, Jul 19, 2019
                                           </span>
                        <em class="fas fa-stopwatch"></em>
                        <span class="reading-time">25-minute read</span>
                    </div>
                    <div>
                    	<hr style="height:1px;border-width:0;background-color:rgba(0,0,0,0.15)">
                    </div>
                
            </div>
            
            
	    <div class="post-content-text">
    	        <p>This blogpost contains code for the <a href="https://www.kaggle.com/c/titanic">Kaggle Titanic challenge</a>. It is a well-known beginner challenge and its goal is to build a binary classification model to predict if passengers would have survived the Titanic disaster or not. The focus of this blogpost is on Exploratory Data Analysis and some Feature Engineering. As usual, the code can also be found in my correspondig <a href="https://github.com/tlary/kaggle_titanic">GitHub repository</a>.</p>
<p>We start off by importing the basic Python libraries that will be needed throughout this notebook and by loading the datasets into pandas DataFrames.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sns</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&#34;train.csv&#34;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&#34;test.csv&#34;</span><span class="p">)</span>
</code></pre></div><h2 id="1-exploratory-data-analysis-eda">1. Exploratory Data Analysis (EDA)</h2>
<p>The first step when tackling a new challenge or project should always be to first get to know the data. Therefore, we will start by looking at the data and the variables.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div><pre><code>((891, 12), (418, 11))
</code></pre>
<p>We see that the training set contains 891 observations (rows) and 12 variables or features (columns). The test set contains less observations (418) and only 11 features.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">columns</span>
</code></pre></div><pre><code>(Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',
        'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],
       dtype='object'),
 Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',
        'Ticket', 'Fare', 'Cabin', 'Embarked'],
       dtype='object'))
</code></pre>
<p>Moreover, both datasets contain exactly the same variables except for &ldquo;Survived&rdquo;, which is missing in the test dataset since this is the variable we want to predict. It is a dummy variable, 1 means survived, 0 means not survived. The &ldquo;Name&rdquo; variable has unique values for every person and does not directly predict the chance of survival. However, we will not drop the feature at this point, but are going to extract some information from it in the section &ldquo;Feature Engineering&rdquo;.</p>
<p>As a next step we can look at the data types of the variables.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">train</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</code></pre></div><pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
PassengerId    891 non-null int64
Survived       891 non-null int64
Pclass         891 non-null int64
Name           891 non-null object
Sex            891 non-null object
Age            714 non-null float64
SibSp          891 non-null int64
Parch          891 non-null int64
Ticket         891 non-null object
Fare           891 non-null float64
Cabin          204 non-null object
Embarked       889 non-null object
dtypes: float64(2), int64(5), object(5)
memory usage: 83.6+ KB
</code></pre>
<p>The variables &ldquo;Sex&rdquo;, &ldquo;Ticket&rdquo;, &ldquo;Cabin&rdquo; and &ldquo;Embarked&rdquo; are categorical data, the remaining features are numerical. We will first look at the numerical variables in more detail and then at the categorical variables.</p>
<p>In order to see which variables have an influence on the chance of survival, we will also investigate the relation between each variable and the target variable &ldquo;Survived&rdquo;.</p>
<h3 id="11-numerical-features">1.1 Numerical Features</h3>
<h4 id="survived">Survived</h4>
<p>We start with the target variable, indicating if a passenger has survived the sinking of the Titanic.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">Survived</span><span class="p">),</span> <span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&#34;Survived&#34;</span><span class="p">)</span>
</code></pre></div><pre><code>(0.3838)
</code></pre>
<p><img src="Titanic_files/Titanic_19_1.png" alt="png"></p>
<p>Around 38,3% of the passengers survived the Titanic.</p>
<h4 id="pclass">Pclass</h4>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">train</span><span class="o">.</span><span class="n">Pclass</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><pre><code>3    491
1    216
2    184
Name: Pclass, dtype: int64
</code></pre>
<p>Pclass is short for Passenger Class and gives the class to which the passengers belong. 1 is the most expensive class, 3 the cheapest one. As expected, most passengers belong to class 3, while class 1 contains the least passengers.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&#34;Pclass&#34;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&#34;Survived&#34;</span><span class="p">)</span>
</code></pre></div><p><img src="Titanic_files/Titanic_24_1.png" alt="png"></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]:</span>
    <span class="k">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">Survived</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]</span><span class="o">==</span><span class="n">i</span><span class="p">]),</span> <span class="mi">4</span><span class="p">))</span>
</code></pre></div><pre><code>0.6296
0.4728
0.2424
</code></pre>
<p>The fraction of passengers, who survived is 63.0% for the first class, 47.3% for the second class and only 24.2% for the third class. The fraction of people surviving is therefore larger than the overall fraction surviving the catastrophe for the first and second class and way below the mean for the third class. We can already see here that the cabin class does play a very important role in surviving and that in the first class almost 2 out of 3 passengers survived.</p>
<h4 id="age">Age</h4>
<p>Since age is a continuous variable, we can display its distribution using a histogram and a kernel density estimator.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Age&#34;</span><span class="p">])</span>
</code></pre></div><p><img src="Titanic_files/Titanic_30_1.png" alt="png"></p>
<p>Running the above code yields an error since there are missing values for Age in the training dataset. Therefore, we first have to fix this issue.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">train</span><span class="o">.</span><span class="n">Age</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</code></pre></div><pre><code>177
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">agemean1</span><span class="p">,</span> <span class="n">agemean2</span><span class="p">,</span> <span class="n">agemean3</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s2">&#34;Age&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]])</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">round</span><span class="p">(</span><span class="n">agemean1</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="nb">round</span><span class="p">(</span><span class="n">agemean2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="nb">round</span><span class="p">(</span><span class="n">agemean3</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div><pre><code>(38.23, 29.88, 25.14)
</code></pre>
<p>There are 177 missing values for the Age. We compute the mean in each class and will use these means to impute the missing values in the training dataset.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">miss_age</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Age&#34;</span><span class="p">])</span>
<span class="n">class_1</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
<span class="n">class_2</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>
<span class="n">class_3</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">3</span>
<span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">class_1</span><span class="p">,</span> <span class="s2">&#34;Age&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">class_1</span><span class="p">,</span> <span class="s2">&#34;Age&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">agemean1</span><span class="p">)</span>
<span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">class_2</span><span class="p">,</span> <span class="s2">&#34;Age&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">class_2</span><span class="p">,</span> <span class="s2">&#34;Age&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">agemean2</span><span class="p">)</span>
<span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">class_3</span><span class="p">,</span> <span class="s2">&#34;Age&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">class_3</span><span class="p">,</span> <span class="s2">&#34;Age&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">agemean3</span><span class="p">)</span>
<span class="n">train</span><span class="o">.</span><span class="n">Age</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</code></pre></div><pre><code>0
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">test</span><span class="o">.</span><span class="n">Age</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</code></pre></div><pre><code>86
</code></pre>
<p>We see that there are also missing values for age in the test data set, therefore we do the same thing for the test dataset.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">agemean_1_test</span><span class="p">,</span> <span class="n">agemean_2_test</span><span class="p">,</span> <span class="n">agemean_3_test</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="s2">&#34;Age&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="n">test</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]])</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">round</span><span class="p">(</span><span class="n">agemean_1_test</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="nb">round</span><span class="p">(</span><span class="n">agemean_2_test</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="nb">round</span><span class="p">(</span><span class="n">agemean_3_test</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div><pre><code>(40.92, 28.78, 24.03)
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">miss_age_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s2">&#34;Age&#34;</span><span class="p">])</span>
<span class="n">class_1_test</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
<span class="n">class_2_test</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>
<span class="n">class_3_test</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">3</span>
<span class="n">test</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">class_1_test</span><span class="p">,</span> <span class="s2">&#34;Age&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">class_1_test</span><span class="p">,</span> <span class="s2">&#34;Age&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">agemean_1_test</span><span class="p">)</span>
<span class="n">test</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">class_2_test</span><span class="p">,</span> <span class="s2">&#34;Age&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">class_2_test</span><span class="p">,</span> <span class="s2">&#34;Age&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">agemean_2_test</span><span class="p">)</span>
<span class="n">test</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">class_3_test</span><span class="p">,</span> <span class="s2">&#34;Age&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">class_3_test</span><span class="p">,</span> <span class="s2">&#34;Age&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">agemean_3_test</span><span class="p">)</span>
<span class="n">test</span><span class="o">.</span><span class="n">Age</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</code></pre></div><pre><code>0
</code></pre>
<p>Now we can again run the above code and plot the histogram.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Age&#34;</span><span class="p">])</span>
</code></pre></div><p><img src="Titanic_files/Titanic_41_1.png" alt="png"></p>
<p>We can also plot the distribution of age by survival.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">grid</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">FacetGrid</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s2">&#34;Survived&#34;</span><span class="p">)</span>
<span class="n">grid</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">,</span> <span class="s2">&#34;Age&#34;</span><span class="p">)</span>
</code></pre></div><p><img src="Titanic_files/Titanic_43_1.png" alt="png"></p>
<h4 id="sibsp">SibSp</h4>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">train</span><span class="o">.</span><span class="n">SibSp</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><pre><code>0    608
1    209
2     28
4     18
3     16
8      7
5      5
Name: SibSp, dtype: int64
</code></pre>
<p>The variable SibSp contains information about the passenger having Siblings or Spouses aboard the Titanic. Most people seem to be alone, or at least without any siblings or spouse. A large number of passengers does have 1 sibling or his/her spouse with them, those are probably mostly married couples. There also seem to be a few families.</p>
<h4 id="parch">Parch</h4>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">train</span><span class="o">.</span><span class="n">Parch</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><pre><code>0    678
1    118
2     80
3      5
5      5
4      4
6      1
Name: Parch, dtype: int64
</code></pre>
<p>Similar to the variable before, &ldquo;Parch&rdquo; states the number of the passenger&rsquo;s parents or children aboard the ship. It also indicates that most passengers are alone, however, there seem to be a few families.</p>
<h4 id="fare">Fare</h4>
<p>First, we take a look at the mean fares in the respective classes.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]:</span>
    <span class="k">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">Fare</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">]),</span> <span class="mi">2</span><span class="p">))</span>
</code></pre></div><pre><code>84.15
20.66
13.68
</code></pre>
<p>As expected, there is a drastic decline in the fare from the first to the third class. Let&rsquo;s see next if there is a systematic difference between the fare of male and female passengers.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]:</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;The Fare for female passengers in Class &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&#34; is: &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Fare&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Sex&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&#34;female&#34;</span><span class="p">)]),</span> <span class="mi">2</span><span class="p">))),</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;The Fare for male passengers in Class &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&#34; is: &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Fare&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Sex&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&#34;male&#34;</span><span class="p">)]),</span> <span class="mi">2</span><span class="p">)))</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
</code></pre></div><pre><code>The Fare for female passengers in Class 1 is: 106.13
The Fare for male passengers in Class 1 is: 67.23


The Fare for female passengers in Class 2 is: 21.97
The Fare for male passengers in Class 2 is: 19.74


The Fare for female passengers in Class 3 is: 16.12
The Fare for male passengers in Class 3 is: 12.66
</code></pre>
<p>The fare seems to be higher for female passengers than for male passengers, this is also consistent over all classes.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">harb</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&#34;C&#34;</span><span class="p">,</span> <span class="s2">&#34;S&#34;</span><span class="p">,</span> <span class="s2">&#34;Q&#34;</span><span class="p">]:</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;Mean fare for passengers embarked in &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">harb</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&#34;: &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">Fare</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Embarked&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="n">harb</span><span class="p">]),</span> <span class="mi">2</span><span class="p">)))</span>
</code></pre></div><pre><code>Mean fare for passengers embarked in C: 59.95
Mean fare for passengers embarked in S: 27.08
Mean fare for passengers embarked in Q: 13.28
</code></pre>
<p>Furthermore, the mean fare is the highest for people from Cherbourg and the lowest from passengers from Queenstown. An explanation for this is given further below (section Categorical Features - Embarked).</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">harb</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&#34;C&#34;</span><span class="p">,</span> <span class="s2">&#34;S&#34;</span><span class="p">,</span> <span class="s2">&#34;Q&#34;</span><span class="p">]:</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;Mean fare for 1st class passengers embarked in &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">harb</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&#34;: &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Fare&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Embarked&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="n">harb</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)]),</span> <span class="mi">2</span><span class="p">)))</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;Mean fare for 2nd class passengers embarked in &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">harb</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&#34;: &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Fare&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Embarked&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="n">harb</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)]),</span> <span class="mi">2</span><span class="p">)))</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;Mean fare for 3rd class passengers embarked in &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">harb</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&#34;: &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Fare&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Embarked&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="n">harb</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">3</span><span class="p">)]),</span> <span class="mi">2</span><span class="p">)))</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>
</code></pre></div><pre><code>Mean fare for 1st class passengers embarked in C: 104.72
Mean fare for 2nd class passengers embarked in C: 25.36
Mean fare for 3rd class passengers embarked in C: 11.21


Mean fare for 1st class passengers embarked in S: 70.36
Mean fare for 2nd class passengers embarked in S: 20.33
Mean fare for 3rd class passengers embarked in S: 14.64


Mean fare for 1st class passengers embarked in Q: 90.0
Mean fare for 2nd class passengers embarked in Q: 12.35
Mean fare for 3rd class passengers embarked in Q: 11.18
</code></pre>
<p>We can see that in addition to the different prices in the respective classes there was some price differentiation between the different harbours with Cherbourg being the most expensive one.</p>
<p>Comments on the relationship of fares and the chance of urvival are made in the next section.</p>
<h4 id="correlation-between-variables">Correlation between variables</h4>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">corr_mat</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;PassengerId&#34;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">corr_mat</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">)</span>
</code></pre></div><p><img src="Titanic_files/Titanic_62_0.png" alt="png"></p>
<p>The above heatmap shows the correlation between all numerical variables including our target variable &ldquo;Survived&rdquo;. A correlation of 1 means a very strong linear relationship, a correlation coefficient of -1 means a very strong negative linear relationship between variables. A correlation of 0 means that the variables do not have a linear relationship at all.</p>
<p>We can learn from the heatmap that there is a pretty strong negative correlation of -0.55 between the class and the fare, which makes sense since tickets for the first and second class are more expensive than for the third class. Furthermore, there seems to be a negative relationship between the class and the chance of survival indicated by the correlation coefficient of -0.34. We have also seen this in the barplots created above. The correlation between the Fare and Survived is pretty strong as well (0.26), which probably stems from the fact that higher fares coincide with a lower (i.e. &ldquo;better&rdquo;) class.
The high correlation between SibSp and Parch of 0.41 lets us assume that there may be some families aboard.</p>
<p>If there is a very high correlation between some variables, these do not contain much new explanatory information in addition to the correlated feature. This can cause the respective estimator to be less precise and is known as multicollinearity. The easiest solution would be to drop one of the features or combining them in some way if possible. Another approach would be to use dimensionality reduction techniques, as for example a principal component analysis (PCA) step to reduce the effective number of features. Since the highest correlation (in absolute values) is -0.55, multicollinearity is not a problem for our data and thus we keep all of the features.</p>
<h3 id="12-categorical-features">1.2 Categorical Features</h3>
<h4 id="sex">Sex</h4>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">train</span><span class="o">.</span><span class="n">Sex</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(),</span> <span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&#34;Sex&#34;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&#34;Survived&#34;</span><span class="p">)</span>
</code></pre></div><pre><code>(male      577
 female    314
 Name: Sex, dtype: int64,
 &lt;AxesSubplot:xlabel='Sex', ylabel='count'&gt;)
</code></pre>
<p><img src="Titanic_files/Titanic_66_1.png" alt="png"></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">Survived</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Sex&#34;</span><span class="p">]</span><span class="o">==</span><span class="s2">&#34;male&#34;</span><span class="p">]),</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">Survived</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Sex&#34;</span><span class="p">]</span><span class="o">==</span><span class="s2">&#34;female&#34;</span><span class="p">]),</span> <span class="mi">4</span><span class="p">))</span>
</code></pre></div><pre><code>0.1889
0.742
</code></pre>
<p>We can see that the number of females that survived is a lot higher than the number of males surviving although there are much more men on the Titanic than women (577 vs. 314). This is also reflected in the fraction of men and women who survived. While only 18.9% of the male passengers survived, over 74% of the female passengers survived the sinking.</p>
<p>Let&rsquo;s take a look if this pattern is consistent through all classes.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;Pclass&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Survived&#39;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;Sex&#39;</span><span class="p">)</span>
</code></pre></div><p><img src="Titanic_files/Titanic_69_1.png" alt="png"></p>
<p>We have qualitatively the same picture for each class, although the survival rates are higher in the more expensive classes in general.</p>
<h4 id="cabin">Cabin</h4>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">train</span><span class="o">.</span><span class="n">Cabin</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><pre><code>C23 C25 C27    4
G6             4
B96 B98        4
F33            3
F2             3
              ..
F E69          1
C45            1
E38            1
C110           1
B69            1
Name: Cabin, Length: 147, dtype: int64
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">train</span><span class="o">.</span><span class="n">Cabin</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</code></pre></div><pre><code>687
</code></pre>
<p>Since there are mostly unique values and 687 missing values we will just drop the column completely.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;Cabin&#34;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;Cabin&#34;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><h4 id="ticket">Ticket</h4>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Ticket&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span>
</code></pre></div><pre><code>&lt;bound method IndexOpsMixin.value_counts of 0             A/5 21171
1              PC 17599
2      STON/O2. 3101282
3                113803
4                373450
             ...       
886              211536
887              112053
888          W./C. 6607
889              111369
890              370376
Name: Ticket, Length: 891, dtype: object&gt;
</code></pre>
<p>The &ldquo;Ticket&rdquo; feature contains the ticket number. These are mainly unique values, therefore not adding much explanatory power to our prediction model. Thus, we just drop this column as well.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;Ticket&#34;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;Ticket&#34;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><h4 id="embarked">Embarked</h4>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">train</span><span class="o">.</span><span class="n">Embarked</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><pre><code>S    644
C    168
Q     77
Name: Embarked, dtype: int64
</code></pre>
<p>The categories of embarkment are C, Q and S which are the first letters of Cherbourg, Queenstown and Southampton. Most passengers are embarked in Southampton, the least frequent category is Queenstown.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">sns</span><span class="o">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&#34;Embarked&#34;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&#34;Survived&#34;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&#34;Sex&#34;</span><span class="p">)</span>
</code></pre></div><p><img src="Titanic_files/Titanic_83_1.png" alt="png"></p>
<p>Interestingly, the fraction of people who survived is higher for Cherbourg. The fraction of male survivors is much higher in Southampton compared to Queenstown, while the fraction of female survivors is higher for Queenstown compared to Southampton. The high survival rates for Cherbourg might be high due to the fact that first class passengers are mostly embarked in Cherbourg, so we will further investigate that now.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">grid</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">FacetGrid</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s2">&#34;Embarked&#34;</span><span class="p">)</span>
<span class="n">grid</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">,</span> <span class="s2">&#34;Pclass&#34;</span><span class="p">)</span>
</code></pre></div><p><img src="Titanic_files/Titanic_85_1.png" alt="png"></p>
<p>Cherbourg is the only category for which the number of first-class passengers is the highest, which confirms the assumption from above. At the same time, mainly passengers from the third class are embarked in Queenstown which explains the low survival rates for male passengers.</p>
<h2 id="2-data-preparation--feature-engineering">2. Data Preparation &amp; Feature Engineering</h2>
<h3 id="21-feature-engineering">2.1 Feature Engineering</h3>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;Survived&#34;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s2">&#34;Survived&#34;</span><span class="p">]</span>
<span class="n">X</span><span class="p">[</span><span class="s2">&#34;train&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">test</span><span class="p">[</span><span class="s2">&#34;train&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">test</span><span class="p">])</span>
<span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div><pre><code>((891, 10), (418, 10), (1309, 10))
</code></pre>
<h4 id="age-band">Age Band</h4>
<p>Since age is a continuous variable, we convert it into a categorical variable consisting of age bands in contrast to the age itself.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span><span class="o">.</span><span class="n">Age</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div><pre><code>count    1309.000000
mean       29.329730
std        13.127747
min         0.170000
25%        22.000000
50%        26.000000
75%        37.000000
max        80.000000
Name: Age, dtype: float64
</code></pre>
<p>The lowest value for Age in our datasets is 0.17 years, the oldest passenger is 80 years old. We want to convert the age into 5 categories. In order to get balanced groups, we will orientate our splitting at percentiles.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span><span class="o">.</span><span class="n">Age</span><span class="o">.</span><span class="n">quantile</span><span class="p">([</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
</code></pre></div><pre><code>0.2    21.00000
0.4    25.14062
0.6    29.87763
0.8    39.00000
Name: Age, dtype: float64
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span><span class="p">[</span><span class="s2">&#34;age_cat&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Age&#34;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">21</span><span class="p">,</span> <span class="s2">&#34;age_cat&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Age&#34;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">20</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Age&#34;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">25</span><span class="p">),</span> <span class="s2">&#34;age_cat&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Age&#34;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">25</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Age&#34;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">30</span><span class="p">),</span> <span class="s2">&#34;age_cat&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Age&#34;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">30</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Age&#34;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">40</span><span class="p">),</span> <span class="s2">&#34;age_cat&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Age&#34;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">40</span><span class="p">,</span> <span class="s2">&#34;age_cat&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span><span class="o">.</span><span class="n">age_cat</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><pre><code>3    318
2    267
1    248
4    240
5    236
Name: age_cat, dtype: int64
</code></pre>
<h4 id="child">Child</h4>
<p>In addition to the age category we just defined, we assume that being a child increases the probability of surviving. Since our youngest age category ranges from newborn to 20-year-olds, this is not really reflected by the data yet. We therefore define a dummy variable indicating if a passenger is a child. We do so by saying that children are people younger than 16.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span><span class="p">[</span><span class="s2">&#34;child&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Age&#34;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">16</span><span class="p">,</span> <span class="s2">&#34;child&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</code></pre></div><p>Since there is a very high positive correlation between Age and the categorical age variable (which is not surprising since it contains mostly the same information just structured), we are going to drop the continuous age variable.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;Age&#34;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><h4 id="fare-bands">Fare bands</h4>
<p>In the same way as with age we can proceed with the fares paid by each passenger. Here, we will not define bands by hand, but we use the pandas function qcut(). We use 10 categories to divide the fares into. After doing so, we can drop the original fare column. However, before we can create the bands, we check for missing values.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Fare&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()]</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="0" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Embarked</th>
      <th>train</th>
      <th>age_cat</th>
      <th>child</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>152</th>
      <td>1044</td>
      <td>3</td>
      <td>Storey, Mr. Thomas</td>
      <td>male</td>
      <td>0</td>
      <td>0</td>
      <td>NaN</td>
      <td>S</td>
      <td>0</td>
      <td>5</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
<p>The observation missing the fare data belongs to the third class and was embarked in are embarked . We will therefore impute the missing with the mean fare of passengers from the third class embarked in are embarked . Since we have seen before that the fares are systematically lower for male passengers, we also take into account that the passenger with the missing fare value is male.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Fare&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">(),</span> <span class="s2">&#34;Fare&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Fare&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">3</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Embarked&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&#34;S&#34;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Sex&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&#34;male&#34;</span><span class="p">)])</span>
</code></pre></div><p>Now we can continue creating the fare categories based on quantiles.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Fare_cat&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">qcut</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Fare&#34;</span><span class="p">],</span> <span class="mi">10</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;Fare&#34;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><h4 id="family-size-sibsp--parch">Family Size SibSp + ParCh</h4>
<p>Since we have information about the number of siblings and spouses and about the number of parents or children for each passenger, we can use these features to create a feature that contains the number of a particular family that was aboard the ship. We call it family_size.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span><span class="p">[</span><span class="s2">&#34;family_size&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;SibSp&#34;</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;Parch&#34;</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">data</span><span class="o">.</span><span class="n">family_size</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><pre><code>1     790
2     235
3     159
4      43
6      25
5      22
7      16
11     11
8       8
Name: family_size, dtype: int64
</code></pre>
<p>We can now drop the features SibSp and Parch.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s2">&#34;SibSp&#34;</span><span class="p">,</span> <span class="s2">&#34;Parch&#34;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><h4 id="title">Title</h4>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span><span class="o">.</span><span class="n">Name</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><pre><code>0                              Braund, Mr. Owen Harris
1    Cumings, Mrs. John Bradley (Florence Briggs Th...
2                               Heikkinen, Miss. Laina
3         Futrelle, Mrs. Jacques Heath (Lily May Peel)
4                             Allen, Mr. William Henry
5                                     Moran, Mr. James
6                              McCarthy, Mr. Timothy J
7                       Palsson, Master. Gosta Leonard
8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)
9                  Nasser, Mrs. Nicholas (Adele Achem)
Name: Name, dtype: object
</code></pre>
<p>Looking at the passenger&rsquo;s names, we notice that there are titles attached to them. The structure of this column is <em>&ldquo;Last name, title first name&rdquo;</em>. We can now extract those titles.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">Name</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&#34;,&#34;</span><span class="p">,</span> <span class="n">expand</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&#34;.&#34;</span><span class="p">,</span> <span class="n">expand</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><pre><code> Mr              757
 Miss            260
 Mrs             197
 Master           61
 Dr                8
 Rev               8
 Col               4
 Mlle              2
 Ms                2
 Major             2
 Jonkheer          1
 Don               1
 Capt              1
 Dona              1
 Mme               1
 Lady              1
 the Countess      1
 Sir               1
Name: Title, dtype: int64
</code></pre>
<p>We see that the most frequent titles are simply Mr and Miss. We also see that there seem to be, for example, many different titles for women, e.g. Miss, Mrs, Ms, Mlle (Mademoiselle). We therefore group the titles into 5 categories: Mr, Mrs (married females), Miss, Master and other.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&#34;Mme&#34;</span><span class="p">,</span> <span class="s2">&#34;Mrs&#34;</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&#34;Mlle&#34;</span><span class="p">,</span> <span class="s2">&#34;Miss&#34;</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&#34;Ms&#34;</span><span class="p">,</span> <span class="s2">&#34;Miss&#34;</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&#34;Dona&#34;</span><span class="p">,</span> <span class="s2">&#34;Other&#34;</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&#34;Don&#34;</span><span class="p">,</span> <span class="s2">&#34;Other&#34;</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&#34;Rev&#34;</span><span class="p">,</span> <span class="s2">&#34;Other&#34;</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&#34;Dr&#34;</span><span class="p">,</span> <span class="s2">&#34;Other&#34;</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&#34;Major&#34;</span><span class="p">,</span> <span class="s2">&#34;Other&#34;</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&#34;Lady&#34;</span><span class="p">,</span> <span class="s2">&#34;Other&#34;</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&#34;Sir&#34;</span><span class="p">,</span> <span class="s2">&#34;Other&#34;</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&#34;Col&#34;</span><span class="p">,</span> <span class="s2">&#34;Other&#34;</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&#34;Capt&#34;</span><span class="p">,</span> <span class="s2">&#34;Other&#34;</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&#34;the Countess&#34;</span><span class="p">,</span> <span class="s2">&#34;Other&#34;</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&#34;Title&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&#34;Jonkheer&#34;</span><span class="p">,</span> <span class="s2">&#34;Other&#34;</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s2">&#34;Title&#34;</span><span class="p">)</span>
</code></pre></div><p><img src="Titanic_files/Titanic_119_1.png" alt="png"></p>
<p>We can now drop the Name column.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;Name&#34;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><h3 id="22-missing-values">2.2 Missing Values</h3>
<p>Before starting the modelling part of this notebook, we take a quick look if there are any missing values in addition to those we already took care of.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</code></pre></div><pre><code>PassengerId    0
Pclass         0
Sex            0
Embarked       2
train          0
age_cat        0
child          0
Fare_cat       0
family_size    0
Title          0
dtype: int64
</code></pre>
<p>There are two more missing values for Embarked. We proceed in a similar manner as we have done so with Age above. However, instead of using means we impute the missings with the most frequent value in the respective class.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Embarked&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()]</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="0" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Embarked</th>
      <th>train</th>
      <th>age_cat</th>
      <th>child</th>
      <th>Fare_cat</th>
      <th>family_size</th>
      <th>Title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>61</th>
      <td>62</td>
      <td>1</td>
      <td>female</td>
      <td>NaN</td>
      <td>1</td>
      <td>4</td>
      <td>0</td>
      <td>(78.02, 512.329]</td>
      <td>1</td>
      <td>Miss</td>
    </tr>
    <tr>
      <th>829</th>
      <td>830</td>
      <td>1</td>
      <td>female</td>
      <td>NaN</td>
      <td>1</td>
      <td>5</td>
      <td>0</td>
      <td>(78.02, 512.329]</td>
      <td>1</td>
      <td>Mrs</td>
    </tr>
  </tbody>
</table>
</div>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Embarked&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><pre><code>S    177
C    141
Q      3
Name: Embarked, dtype: int64
</code></pre>
<p>The most frequent value of Embarked for passengers in the first class is Southhampton.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;Embarked&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">(),</span> <span class="s2">&#34;Embarked&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&#34;S&#34;</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</code></pre></div><pre><code>PassengerId    0
Pclass         0
Sex            0
Embarked       0
train          0
age_cat        0
child          0
Fare_cat       0
family_size    0
Title          0
dtype: int64
</code></pre>
<p>Our data looks good now, there are no more missing values.</p>
<h3 id="23-dummy-variables">2.3 Dummy variables</h3>
<p>sklearn cannot handle categorical data, therefore we need to transform categorical features into dummy variables. If we have, for example, sex as a categorical feature (&ldquo;male&rdquo; or &ldquo;female&rdquo;) and we convert this feature into dummies we get one dummy for &ldquo;male&rdquo; (0: no, 1: yes) and one for &ldquo;female&rdquo;. Since both features are just linear combinations of each other (i.e. if we have the value for &ldquo;male&rdquo; we also have the value for &ldquo;female&rdquo;) this would cause perfect multicollinearity. We therefore drop the first category dummy per feature to prevent this.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">drop_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div><p>We can now split our data into the training and the test set. To do so, we have defined a binary variable &ldquo;train&rdquo; before concatenating both data frames. We can now use this indicator to split them again. After doing so, we drop the PassengerId since it does not add any information to our model.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;train&#34;</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;PassengerId&#34;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s2">&#34;train&#34;</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ID</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="s2">&#34;PassengerId&#34;</span><span class="p">]</span> <span class="c1"># saving the test set PassengerId for submission file</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;PassengerId&#34;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div><pre><code>((891, 24), (891,), (418, 24))
</code></pre>
<h2 id="3-building-the-predictive-models">3. Building the Predictive Models</h2>
<p>We will try two different algorithms: a Random Forest Classifier and XGBoost Classifier. Since the Kaggle Leaderboard is based on the accuracy, i.e. the percentage of correctly classified samples, we will also use this metric to evaluate our models using k-fold cross-validation on a hold-out (test) set.</p>
<h3 id="31-random-forest">3.1 Random Forest</h3>
<p>We are going to start with the Random Forest Classifier.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RandomizedSearchCV</span>
</code></pre></div><p>At first. we have to split our data into a training set and a test set, on which the models can be evaluated on later.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
                                                    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> 
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
<span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div><pre><code>((712, 24), (179, 24), (712,), (179,))
</code></pre>
<p>Then we will create our pipeline object, define the functions that should be applied and define a grid with the parameters we want to tune and the range from which <code>RandomizedSearchCV()</code> should draw from.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">steps_rf</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&#34;scaler&#34;</span><span class="p">,</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">()),</span> 
            <span class="p">(</span><span class="s2">&#34;rf_class&#34;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">))]</span>
<span class="n">pipeline_rf</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps_rf</span><span class="p">)</span>

<span class="c1"># define our hyperparameter grid</span>
<span class="n">n_estimators</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">2001</span><span class="p">,</span> <span class="mi">200</span><span class="p">))</span>
<span class="n">max_features</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;auto&#34;</span><span class="p">,</span> <span class="s2">&#34;sqrt&#34;</span><span class="p">,</span> <span class="s2">&#34;log2&#34;</span><span class="p">]</span>
<span class="n">max_depth</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">max_depth</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
<span class="n">min_samples_split</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="n">bootstrap</span> <span class="o">=</span> <span class="p">[</span><span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">]</span>
<span class="n">param_dist</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;rf_class__n_estimators&#34;</span><span class="p">:</span> <span class="n">n_estimators</span><span class="p">,</span>
              <span class="s2">&#34;rf_class__max_features&#34;</span><span class="p">:</span> <span class="n">max_features</span><span class="p">,</span>
              <span class="s2">&#34;rf_class__max_depth&#34;</span><span class="p">:</span> <span class="n">max_depth</span><span class="p">,</span>
              <span class="s2">&#34;rf_class__min_samples_split&#34;</span><span class="p">:</span> <span class="n">min_samples_split</span><span class="p">,</span>
              <span class="s2">&#34;rf_class__min_samples_leaf&#34;</span><span class="p">:</span> <span class="n">min_samples_leaf</span><span class="p">,</span>
              <span class="s2">&#34;rf_class__bootstrap&#34;</span><span class="p">:</span> <span class="n">bootstrap</span><span class="p">}</span>
</code></pre></div><p>We can now start to narrow down the range for our hyperparameters by using <code>RandomizedSearchCV()</code> to get a first hint of the ideally chosen hyperparameters for our data.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cv_random_rf</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">pipeline_rf</span><span class="p">,</span> <span class="n">param_dist</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
                                  <span class="n">n_jobs</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cv_random_rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div><pre><code>Fitting 5 folds for each of 50 candidates, totalling 250 fits
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cv_random_rf</span><span class="o">.</span><span class="n">best_params_</span>
</code></pre></div><pre><code>{'rf_class__n_estimators': 2000,
 'rf_class__min_samples_split': 10,
 'rf_class__min_samples_leaf': 4,
 'rf_class__max_features': 'auto',
 'rf_class__max_depth': 70,
 'rf_class__bootstrap': True}
</code></pre>
<p>Based on the chosen parameters from <code>RandomizedSearchCV()</code> we can now manually decrease the range of the hyperparameters to be tested and use <code>GridSearchCV()</code> as before to find the best parameters for our model.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">n_estimators_2</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1800</span><span class="p">,</span> <span class="mi">2001</span><span class="p">,</span> <span class="mi">50</span><span class="p">))</span>
<span class="n">max_depth_2</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">91</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">max_features_2</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;auto&#34;</span><span class="p">]</span>
<span class="n">min_samples_split_2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">]</span>
<span class="n">min_samples_leaf_2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>
<span class="n">bootstrap_2</span> <span class="o">=</span> <span class="p">[</span><span class="bp">True</span><span class="p">]</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;rf_class__n_estimators&#34;</span><span class="p">:</span> <span class="n">n_estimators_2</span><span class="p">,</span>
              <span class="s2">&#34;rf_class__max_depth&#34;</span><span class="p">:</span> <span class="n">max_depth_2</span><span class="p">,</span>
              <span class="s2">&#34;rf_class__max_features&#34;</span><span class="p">:</span> <span class="n">max_features_2</span><span class="p">,</span>
              <span class="s2">&#34;rf_class__min_samples_split&#34;</span><span class="p">:</span> <span class="n">min_samples_split_2</span><span class="p">,</span>
              <span class="s2">&#34;rf_class__min_samples_leaf&#34;</span><span class="p">:</span> <span class="n">min_samples_leaf_2</span><span class="p">,</span>
              <span class="s2">&#34;rf_class__bootstrap&#34;</span><span class="p">:</span> <span class="n">bootstrap_2</span><span class="p">}</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cv_rf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipeline_rf</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">cv_rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cv_rf</span><span class="o">.</span><span class="n">best_params_</span>
</code></pre></div><pre><code>{'rf_class__bootstrap': True,
 'rf_class__max_depth': 50,
 'rf_class__max_features': 'auto',
 'rf_class__min_samples_leaf': 4,
 'rf_class__min_samples_split': 10,
 'rf_class__n_estimators': 1800}
</code></pre>
<p>We now can evaluate our model on our hold out test set using the accuracy metric.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">y_pred_rf</span> <span class="o">=</span> <span class="n">cv_rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">round</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_rf</span><span class="p">),</span> <span class="mi">4</span><span class="p">)</span>
</code></pre></div><pre><code>0.8547
</code></pre>
<p>We get an accuracy of 0.8547, which means that the model correctly classified 85.5% of the unseen test data, which is pretty good. We can also plot the confusion matrix.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cm_rf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_rf</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.4</span><span class="p">)</span>
<span class="n">cm_rf</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm_rf</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&#34;g&#34;</span><span class="p">)</span>
<span class="n">cm_rf</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&#34;True label&#34;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&#34;Predicted Label&#34;</span><span class="p">)</span>
</code></pre></div><p><img src="Titanic_files/Titanic_157_1.png" alt="png"></p>
<p>We can now run our model on the test set provided by Kaggle to see how well our model performs in the challenge compared to other models.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">pred_rf</span> <span class="o">=</span> <span class="n">cv_rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
<span class="n">submiss_rf</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;PassengerId&#34;</span><span class="p">:</span><span class="n">ID</span><span class="p">,</span> <span class="s2">&#34;Survived&#34;</span><span class="p">:</span> <span class="n">pred_rf</span><span class="p">}</span>
<span class="n">submission_rf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">submiss_rf</span><span class="p">)</span>
</code></pre></div><h3 id="32-xgboost">3.2 XGBoost</h3>
<p>After the random forest, we will now try the XGBoost algorithm with our data.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">xgboost</span> <span class="kn">as</span> <span class="nn">xgb</span>
<span class="kn">from</span> <span class="nn">xgboost.sklearn</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">steps_xgb</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&#34;scaler&#34;</span><span class="p">,</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">()),</span> 
             <span class="p">(</span><span class="s2">&#34;xgb&#34;</span><span class="p">,</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">objective</span><span class="o">=</span><span class="s2">&#34;binary:logistic&#34;</span><span class="p">,</span> 
                                   <span class="n">eval_metric</span><span class="o">=</span><span class="s2">&#34;auc&#34;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">))]</span>
<span class="n">pipeline_xgb</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps_xgb</span><span class="p">)</span>
</code></pre></div><p>As already done so with our Random Forest model, we first define a grid of hyperparameters and then tune these using RandomizedSearchCV and then GridSearchCV.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">learning_rate</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.311</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">))</span>
<span class="n">max_depth</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">51</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">min_child_weight</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">colsample_bytree</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.91</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">))</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]</span>
<span class="n">n_estimators</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">1001</span><span class="p">,</span><span class="mi">100</span><span class="p">))</span>
<span class="n">param_dist_xgb</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;xgb__learning_rate&#34;</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
              <span class="s2">&#34;xgb__max_depth&#34;</span><span class="p">:</span> <span class="n">max_depth</span><span class="p">,</span>
              <span class="s2">&#34;xgb__min_child_weight&#34;</span><span class="p">:</span> <span class="n">min_child_weight</span><span class="p">,</span>
              <span class="s2">&#34;xgb__colsample_bytree&#34;</span><span class="p">:</span> <span class="n">colsample_bytree</span><span class="p">,</span>
              <span class="s2">&#34;xgb__gamma&#34;</span><span class="p">:</span> <span class="n">gamma</span><span class="p">,</span>
              <span class="s2">&#34;xgb__n_estimators&#34;</span><span class="p">:</span> <span class="n">n_estimators</span><span class="p">}</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cv_random_xgb</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">pipeline_xgb</span><span class="p">,</span> <span class="n">param_dist_xgb</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
                                   <span class="n">n_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cv_random_xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div><p>We can now again use the best hyperparameters found by RandomizedSearchCV to do a grid search on a smaller band of hyperparameters to find the best performing ones.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cv_random_xgb</span><span class="o">.</span><span class="n">best_params_</span>
</code></pre></div><pre><code>{'xgb__colsample_bytree': 0.8000000000000003,
 'xgb__gamma': 4,
 'xgb__learning_rate': 0.23,
 'xgb__max_depth': 40,
 'xgb__min_child_weight': 2,
 'xgb__n_estimators': 200}
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">learning_rate_2</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.26</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">))</span>
<span class="n">max_depth_2</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">35</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">min_child_weight_2</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">colsample_bytree_2</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">))</span>
<span class="n">gamma_2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]</span>
<span class="n">n_estimators_2</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">301</span><span class="p">,</span><span class="mi">100</span><span class="p">))</span>
<span class="n">params_xgb</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;xgb__learning_rate&#34;</span><span class="p">:</span> <span class="n">learning_rate_2</span><span class="p">,</span>
              <span class="s2">&#34;xgb__max_depth&#34;</span><span class="p">:</span> <span class="n">max_depth_2</span><span class="p">,</span>
              <span class="s2">&#34;xgb__min_child_weight&#34;</span><span class="p">:</span> <span class="n">min_child_weight_2</span><span class="p">,</span>
              <span class="s2">&#34;xgb__colsample_bytree&#34;</span><span class="p">:</span> <span class="n">colsample_bytree_2</span><span class="p">,</span>
              <span class="s2">&#34;xgb__gamma&#34;</span><span class="p">:</span> <span class="n">gamma_2</span><span class="p">,</span>
              <span class="s2">&#34;xgb__n_estimators&#34;</span><span class="p">:</span> <span class="n">n_estimators_2</span><span class="p">}</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cv_xgb</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipeline_xgb</span><span class="p">,</span> <span class="n">params_xgb</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">cv_xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">y_pred_xgb</span> <span class="o">=</span> <span class="n">cv_xgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_xgb</span><span class="p">)</span>
</code></pre></div><pre><code>0.8547
</code></pre>
<p>We get an accuracy of 0.8547 using the tuned XGBoost Classifier, which is exactly the same accuracy score as for the RandomForestRegressor. It would be interesting to see which of these models performs better on the unseen test dataset evaluated on Kaggle. We will do a short comparison at the end of this blogpost.
We can again plot the confusion matrix to visualize the predictions and the true values of the hold out set.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cm_xgb_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_xgb</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.4</span><span class="p">)</span>
<span class="n">cm_xgb</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm_xgb_df</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&#34;g&#34;</span><span class="p">)</span>
<span class="n">cm_xgb</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&#34;True label&#34;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&#34;Predicted Label&#34;</span><span class="p">)</span>
</code></pre></div><p><img src="Titanic_files/Titanic_174_1.png" alt="png"></p>
<p>The last step now is to predict the labels on the test set, create a dataframe containing the passengers&rsquo; ID and if they survived or not and to download this, so it can be uploaded to Kaggle and evaluated there.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">pred_xgb</span> <span class="o">=</span> <span class="n">cv_xgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
<span class="n">submiss_xgb</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;PassengerId&#34;</span><span class="p">:</span><span class="n">ID</span><span class="p">,</span> <span class="s2">&#34;Survived&#34;</span><span class="p">:</span> <span class="n">pred_xgb</span><span class="p">}</span>
<span class="n">submission_xgb</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">submiss_xgb</span><span class="p">)</span>
</code></pre></div><h3 id="33-comparison-of-kaggle-results">3.3 Comparison of Kaggle results</h3>
<p>Uploading both submission files, we get an accuracy score of 0.79425 using the RandomForestClassifier built at first. The XGBoost Classifier yields an accuracy score of 0.77511. Thus, the RandomForest clearly outperforms the XGBoost algorithm, which is surprising since XGBoost is known to be the best working algorithm for a very large field of applications for both regression and classification.</p>
<h2 id="4-2021-update-building-a-ml-app-using-streamlit">4. 2021 Update: Building a ML app using Streamlit</h2>
<p><a href="../../post/genre_streamlit/">In another blogpost</a>, I showcased how easy it is to deploy a ML model into a good-looking webapp built with the Streamlit package. To introduce a few more of Streamlit&rsquo;s widgets and elements, I will provide another brief example here using the Titanic challenge.</p>
<h3 id="41-data-preparation">4.1 Data Preparation</h3>
<p>I used a reduced form of the dataset since the focus here is not on the modeling part. Therefore, our model uses only the following variables:</p>
<ul>
<li>age</li>
<li>class</li>
<li>child dummy</li>
<li>family size</li>
<li>embarked</li>
<li>sex</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&#34;train.csv&#34;</span><span class="p">)</span> <span class="c1"># read in data</span>
<span class="c1"># age</span>
<span class="n">agemean1</span><span class="p">,</span> <span class="n">agemean2</span><span class="p">,</span> <span class="n">agemean3</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s2">&#34;Age&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]])</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">miss_age</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Age&#34;</span><span class="p">])</span>
<span class="n">class_1</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
<span class="n">class_2</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>
<span class="n">class_3</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s2">&#34;Pclass&#34;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">3</span>
<span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">class_1</span><span class="p">,</span> <span class="s2">&#34;Age&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">class_1</span><span class="p">,</span> <span class="s2">&#34;Age&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">agemean1</span><span class="p">)</span>
<span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">class_2</span><span class="p">,</span> <span class="s2">&#34;Age&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">class_2</span><span class="p">,</span> <span class="s2">&#34;Age&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">agemean2</span><span class="p">)</span>
<span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">class_3</span><span class="p">,</span> <span class="s2">&#34;Age&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">class_3</span><span class="p">,</span> <span class="s2">&#34;Age&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">agemean3</span><span class="p">)</span>
<span class="n">train</span><span class="o">.</span><span class="n">Age</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">Age</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="c1"># convert class to object</span>
<span class="n">train</span><span class="o">.</span><span class="n">Pclass</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">Pclass</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">object</span><span class="p">)</span>

<span class="c1"># drop cabin and ticket</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;Cabin&#34;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;Ticket&#34;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># child dummy</span>
<span class="n">train</span><span class="p">[</span><span class="s2">&#34;child&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Age&#34;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">16</span><span class="p">,</span> <span class="s2">&#34;child&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># drop fare variable</span>
<span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;Fare&#34;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># create family size, i.e. oneself + children + spouse</span>
<span class="n">train</span><span class="p">[</span><span class="s2">&#34;family_size&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s2">&#34;SibSp&#34;</span><span class="p">]</span> <span class="o">+</span> <span class="n">train</span><span class="p">[</span><span class="s2">&#34;Parch&#34;</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s2">&#34;SibSp&#34;</span><span class="p">,</span> <span class="s2">&#34;Parch&#34;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># drop name variable</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;Name&#34;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># embarked</span>
<span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="s2">&#34;Embarked&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">(),</span> <span class="s2">&#34;Embarked&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&#34;S&#34;</span>

<span class="c1"># drop passenger id</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;PassengerId&#34;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># create dummy variables</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">drop_first</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div><h3 id="42-building-the-toy-model">4.2 Building the Toy Model</h3>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RandomizedSearchCV</span>
<span class="kn">import</span> <span class="nn">pickle</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">Survived</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&#34;Survived&#34;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># initialize the model</span>
<span class="n">steps_rf</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&#34;rf_class&#34;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">))]</span>
<span class="n">pipeline_rf</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps_rf</span><span class="p">)</span>

<span class="c1"># define the hyperparameter grid for RandomSearch</span>
<span class="n">n_estimators</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">2001</span><span class="p">,</span> <span class="mi">200</span><span class="p">))</span>
<span class="n">max_features</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;auto&#34;</span><span class="p">,</span> <span class="s2">&#34;sqrt&#34;</span><span class="p">,</span> <span class="s2">&#34;log2&#34;</span><span class="p">]</span>
<span class="n">max_depth</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">max_depth</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
<span class="n">min_samples_split</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="n">bootstrap</span> <span class="o">=</span> <span class="p">[</span><span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">]</span>
<span class="n">param_dist</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;rf_class__n_estimators&#34;</span><span class="p">:</span> <span class="n">n_estimators</span><span class="p">,</span>
              <span class="s2">&#34;rf_class__max_features&#34;</span><span class="p">:</span> <span class="n">max_features</span><span class="p">,</span>
              <span class="s2">&#34;rf_class__max_depth&#34;</span><span class="p">:</span> <span class="n">max_depth</span><span class="p">,</span>
              <span class="s2">&#34;rf_class__min_samples_split&#34;</span><span class="p">:</span> <span class="n">min_samples_split</span><span class="p">,</span>
              <span class="s2">&#34;rf_class__min_samples_leaf&#34;</span><span class="p">:</span> <span class="n">min_samples_leaf</span><span class="p">,</span>
              <span class="s2">&#34;rf_class__bootstrap&#34;</span><span class="p">:</span> <span class="n">bootstrap</span><span class="p">}</span>

<span class="c1"># RandomSearchCV</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">pipeline_rf</span><span class="p">,</span> <span class="n">param_dist</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
                        <span class="n">n_jobs</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Save to file in the current working directory</span>
<span class="n">pkl_filename</span> <span class="o">=</span> <span class="s2">&#34;rfSimple.pkl&#34;</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">pkl_filename</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> <span class="nb">file</span><span class="p">)</span>
</code></pre></div><h3 id="43-building-the-web-app">4.3 Building the Web App</h3>
<p>We are going to use a range of Streamlit widgets for the users to provide their information on the above listed variables. These inputs will then be collected and put into a pandas DataFrame, which is going to be used as input data for the prediction model. Instead of printing the predicted class only, i.e. if a passenger would have survived or not based on the model, we will output the survival probability, which is simply the probability of belonging to the &ldquo;Survived&rdquo; class.</p>
<p>We use the following widgets: fields for number inputs for the age and family size variables, a selectbox for the passenger class, in which the user can choose Class 1, Class 2, or Class 3; and a selectbox with a binary choice for the sex variable.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">Age</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">sidebar</span><span class="o">.</span><span class="n">number_input</span><span class="p">(</span><span class="s2">&#34;How old are you?&#34;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">family_size</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">sidebar</span><span class="o">.</span><span class="n">number_input</span><span class="p">(</span><span class="s2">&#34;How many family members are aboard the &#34;</span> \
                                      <span class="s2">&#34;ship (including yourself)?&#34;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">pclassAux</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">sidebar</span><span class="o">.</span><span class="n">selectbox</span><span class="p">(</span><span class="s2">&#34;In which passenger class are you traveling?&#34;</span><span class="p">,</span> 
                                <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">sex</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">sidebar</span><span class="o">.</span><span class="n">selectbox</span><span class="p">(</span><span class="s2">&#34;Are you male or female?&#34;</span><span class="p">,</span> <span class="p">(</span><span class="s2">&#34;male&#34;</span><span class="p">,</span> <span class="s2">&#34;female&#34;</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><p>To get the data into the required input format, we use this information to build the DataFrame and create the features we need from it, e.g. creating dummy variables. The whole script then looks as follows:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">streamlit</span> <span class="kn">as</span> <span class="nn">st</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="c1"># load the Random Forest Classifier</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&#34;./rfSimple.pkl&#34;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
    <span class="n">rf</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">file</span><span class="p">)</span>


<span class="c1"># the model takes the following variables as input:</span>
    <span class="c1"># Age - int</span>
    <span class="c1"># child - int</span>
    <span class="c1"># family_size - int</span>
    <span class="c1"># Pclass_1 - uint8</span>
    <span class="c1"># Pclass_2 - uint8</span>
    <span class="c1"># Pclass_3 - uint8</span>
    <span class="c1"># Sex_female - uint8</span>
    <span class="c1"># Sex_male - uint8</span>
    <span class="c1"># Embarked_C - uint8</span>
    <span class="c1"># Embarked_Q - uint8</span>
    <span class="c1"># Embarked_S - uint8</span>

<span class="c1"># create model input</span>
<span class="n">Age</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">sidebar</span><span class="o">.</span><span class="n">number_input</span><span class="p">(</span><span class="s2">&#34;How old are you?&#34;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">child</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">Age</span> <span class="o">&lt;=</span> <span class="mi">16</span><span class="p">)</span>
<span class="n">family_size</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">sidebar</span><span class="o">.</span><span class="n">number_input</span><span class="p">(</span><span class="s2">&#34;How many family members are aboard the &#34;</span> \
                                      <span class="s2">&#34;ship (including yourself)?&#34;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">pclassAux</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">sidebar</span><span class="o">.</span><span class="n">selectbox</span><span class="p">(</span><span class="s2">&#34;In which passenger class are you traveling?&#34;</span><span class="p">,</span> 
                                <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">Pclass_1</span><span class="o">=</span><span class="mi">0</span>
<span class="n">Pclass_2</span><span class="o">=</span><span class="mi">0</span>
<span class="n">Pclass_3</span><span class="o">=</span><span class="mi">0</span>
<span class="k">if</span> <span class="n">pclassAux</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
    <span class="n">Pclass_1</span><span class="o">=</span><span class="mi">1</span>
<span class="k">if</span> <span class="n">pclassAux</span><span class="o">==</span><span class="mi">2</span><span class="p">:</span>
    <span class="n">Pclass_2</span><span class="o">=</span><span class="mi">1</span>
<span class="k">if</span> <span class="n">pclassAux</span><span class="o">==</span><span class="mi">3</span><span class="p">:</span>
    <span class="n">Pclass_3</span><span class="o">=</span><span class="mi">1</span>
<span class="n">sex</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">sidebar</span><span class="o">.</span><span class="n">selectbox</span><span class="p">(</span><span class="s2">&#34;Are you male or female?&#34;</span><span class="p">,</span> <span class="p">(</span><span class="s2">&#34;male&#34;</span><span class="p">,</span> <span class="s2">&#34;female&#34;</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">Sex_female</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">Sex_male</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">if</span> <span class="n">sex</span><span class="o">==</span><span class="s2">&#34;female&#34;</span><span class="p">:</span>
    <span class="n">Sex_female</span><span class="o">=</span><span class="mi">1</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">Sex_male</span><span class="o">=</span><span class="mi">1</span>
<span class="n">embarked</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">sidebar</span><span class="o">.</span><span class="n">selectbox</span><span class="p">(</span><span class="s2">&#34;Which is your port of Embarkation?&#34;</span><span class="p">,</span> 
                               <span class="p">(</span><span class="s2">&#34;Cherbourg&#34;</span><span class="p">,</span> <span class="s2">&#34;Queenstown&#34;</span><span class="p">,</span> <span class="s2">&#34;Southhampton&#34;</span><span class="p">))</span>
<span class="n">Embarked_C</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">Embarked_Q</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">Embarked_S</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># create input DataFrame</span>
<span class="n">inputDF</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&#34;Age&#34;</span><span class="p">:</span> <span class="n">Age</span><span class="p">,</span>
                        <span class="s2">&#34;child&#34;</span><span class="p">:</span> <span class="n">child</span><span class="p">,</span>
                        <span class="s2">&#34;family_size&#34;</span><span class="p">:</span> <span class="n">family_size</span><span class="p">,</span>
                        <span class="s2">&#34;Pclass_1&#34;</span><span class="p">:</span> <span class="n">Pclass_1</span><span class="p">,</span>
                        <span class="s2">&#34;Pclass_2&#34;</span><span class="p">:</span> <span class="n">Pclass_2</span><span class="p">,</span>
                        <span class="s2">&#34;Pclass_3&#34;</span><span class="p">:</span> <span class="n">Pclass_3</span><span class="p">,</span>
                        <span class="s2">&#34;Sex_female&#34;</span><span class="p">:</span> <span class="n">Sex_female</span><span class="p">,</span>
                        <span class="s2">&#34;Sex_male&#34;</span><span class="p">:</span> <span class="n">Sex_male</span><span class="p">,</span>
                        <span class="s2">&#34;Embarked_C&#34;</span><span class="p">:</span> <span class="n">Embarked_C</span><span class="p">,</span>
                        <span class="s2">&#34;Embarked_Q&#34;</span><span class="p">:</span> <span class="n">Embarked_Q</span><span class="p">,</span>
                        <span class="s2">&#34;Embarked_S&#34;</span><span class="p">:</span> <span class="n">Embarked_S</span><span class="p">},</span>
                                 <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">SurvivalProba</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">inputDF</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">survPerc</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">SurvivalProba</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># display survival probability</span>
<span class="n">st</span><span class="o">.</span><span class="n">image</span><span class="p">(</span><span class="s2">&#34;./static/titanic.jpg&#34;</span><span class="p">,</span> <span class="n">use_column_width</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">st</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&#34;Your Survival Probability based on the information &#34;</span> \
         <span class="s2">&#34;provided is: {}%.&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">survPerc</span><span class="p">))</span>
</code></pre></div><p>Note that we put all of the input variables into a collapsible sidebar (<code>st.sidebar.</code>). Again, because of its simplicity, I deployed the app using Streamlit Sharing again. It can be accessed <a href="https://share.streamlit.io/tlary/kaggle_titanic/main.py">here</a> or by clicking on the badge below.</p>
<p><a href="https://share.streamlit.io/tlary/kaggle_titanic/main.py"><img src="https://static.streamlit.io/badges/streamlit_badge_black_white.svg" alt="Open in Streamlit"></a></p>

            </div></div>
        
        

        
    </div>
    


        </div>
    </div>
</div>

<script type="text/javascript"
        src="../../js/jquery.min.86b1e8f819ee2d9099a783e50b49dff24282545fc40773861f9126b921532e4c.js"
        integrity="sha256-hrHo&#43;BnuLZCZp4PlC0nf8kKCVF/EB3OGH5EmuSFTLkw="
        crossorigin="anonymous"></script>




<script type="text/javascript"
        src="../../js/bundle.min.0f9c74cb78f13d1f15f33daff4037c70354f98acfbb97a6f61708966675c3cae.js"
        integrity="sha256-D5x0y3jxPR8V8z2v9AN8cDVPmKz7uXpvYXCJZmdcPK4="
        crossorigin="anonymous"></script>

<script type="text/javascript"
        src="../../js/medium-zoom.min.92f21c856129f84aeb719459b3e6ac621a3032fd7b180a18c04e1d12083f8aba.js"
        integrity="sha256-kvIchWEp&#43;ErrcZRZs&#43;asYhowMv17GAoYwE4dEgg/iro="
        crossorigin="anonymous"></script>
<link rel="stylesheet"
              href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
              integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/&#43;DiW/UqRcLbRjq"
              crossorigin="anonymous"><script defer
                src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
                integrity="sha384-y23I5Q6l&#43;B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd&#43;qj&#43;o24G5ZU2zJz"
                crossorigin="anonymous"></script><script defer
                src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
                integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI"
                crossorigin="anonymous"
                onload="renderMathInElement(document.body);"></script></body>

</html>