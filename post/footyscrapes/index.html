<!DOCTYPE html>
<html lang="en" data-theme=""><head>
    <title> Tobias Larysch | The beautiful Game - Scraping xG and xGA from understat.com </title>

    
    <meta charset="utf-8"><meta name="generator" content="Hugo 0.74.3" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
    <meta name="description" content="Economist and Data Enthusiast">
    
    <link rel="stylesheet"
          href="../../css/style.min.9a6700e4461b50dccdddfc4f81dc65d77e7fca22c35665e398a0c36568db59c7.css"
          integrity="sha256-mmcA5EYbUNzN3fxPgdxl135/yiLDVmXjmKDDZWjbWcc="
          crossorigin="anonymous"
          type="text/css">
    
    <link rel="stylesheet"
        href="../../css/markupHighlight.min.9755453ffb7bc4cd220f86ebb5922107b49f193cc62fc17e9785d27b33a8bf5b.css"
        integrity="sha256-l1VFP/t7xM0iD4brtZIhB7SfGTzGL8F&#43;l4XSezOov1s="
        crossorigin="anonymous"
        type="text/css">
    
        
        
        <link rel="stylesheet"
        href="../../css/custom4.min.a3743a721050fed88609bf3cfff13085cb2546c9ad6f7e13b6e3caf42c4c9305.css"
        integrity="sha256-o3Q6chBQ/tiGCb88//EwhcslRsmtb34TtuPK9CxMkwU="
        crossorigin="anonymous"
        media="screen" />
    
        
        
        <link rel="stylesheet"
        href="../../css/friend.min.d0809843e4028aaa20decda8dda26d1a3bae5e47e87311da5a10b607f015390a.css"
        integrity="sha256-0ICYQ&#43;QCiqog3s2o3aJtGjuuXkfocxHaWhC2B/AVOQo="
        crossorigin="anonymous"
        media="screen" />
    
    <link rel="stylesheet" 
    href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css" 
    integrity="sha512-+4zCK9k+qNFUR5X+cKL9EIR+ZOhtIloNl9GIKS57V1MyNsYpYcUrUeQc9vNfzsWfV28IaLL3i96P9sdNyeRssA==" 
    crossorigin="anonymous" />

    
    <link rel="shortcut icon" href="../../favicons/favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon" sizes="180x180" href="../../favicons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../../favicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../../favicons/favicon-16x16.png">

    <link rel="canonical" href="../../post/footyscrapes/">

    
    
    
    
    <script type="text/javascript"
            src="../../js/anatole-header.min.d8599ee07b7d3f11bafbac30657ccc591e8d7fd36a9f580cd4c09e24e0e4a971.js"
            integrity="sha256-2Fme4Ht9PxG6&#43;6wwZXzMWR6Nf9Nqn1gM1MCeJODkqXE="
            crossorigin="anonymous"></script>


    <script type="text/javascript"
            src="../../js/custom.min.adead2e63eefe548b5ce0aa68303df62a2e2e975242f58d58c080fb3a61e11d7.js"
            integrity="sha256-rerS5j7v5Ui1zgqmgwPfYqLi6XUkL1jVjAgPs6YeEdc="
            crossorigin="anonymous"></script>
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="The beautiful Game - Scraping xG and xGA from understat.com"/>
<meta name="twitter:description" content="This blogpost contains the code for a Web Scraping project to extract the soccer metrics expected goals (xG) and expected goals against (xGA) from understat.com as well as additional match statistics. The code works for all listed leagues and seasons."/>


    
	<script async src="https://cdn.panelbear.com/analytics.js?site=cIJFGgu2o5"></script>
	<script>
    	window.panelbear = window.panelbear || function() { (window.panelbear.q = window.panelbear.q || []).push(arguments); };
    	panelbear('config', { site: 'cIJFGgu2o5' });
	</script>
</head>
<body><div class="sidebar . ">
    <div class="logo-title">
        <div class="title">
            <img src="../../images/foto_cropped.jpg" alt="profile picture">
            <h3 title=""><a href="../../">Tobias Larysch - Portfolio</a></h3>
            <div class="description">
                <p>Economist and Data Enthusiast</p>
            </div>
        </div>
    </div>
    <ul class="social-links">
        
            <li>
                <a href="https://www.linkedin.com/in/tobias-larysch-97981519b/" rel="me" aria-label="Linkedin">
                    <i class="fab fa-linkedin fa-2x" aria-hidden="true"></i>
                </a>
            </li>
        
            <li>
                <a href="https://github.com/tlary" rel="me" aria-label="GitHub">
                    <i class="fab fa-github fa-2x" aria-hidden="true"></i>
                </a>
            </li>
        
            <li>
                <a href="mailto:tobias-larysch@gmx.net" rel="me" aria-label="e-mail">
                    <i class="fas fa-envelope fa-2x" aria-hidden="true"></i>
                </a>
            </li>
        
            <li>
                <a href="https://www.xing.com/profile/Tobias_Larysch/cv" rel="me" aria-label="Xing">
                    <i class="fab fa-xing fa-2x" aria-hidden="true"></i>
                </a>
            </li>
        
    </ul>
    <div class="footer">
        <div class="by_farbox">&copy; Tobias Larysch  2021 </div>
    </div>
</div>
<div class="main">
    <div class="page-top  . ">
    <a role="button" class="navbar-burger" data-target="navMenu" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
    </a>
    <ul class="nav" id="navMenu">
        
        
            
            <li><a 
                   href="../../"
                        
                   title="">Projects </a></li>
        
            
            <li><a 
                   href="../../publications/"
                        
                   title="">Publications</a></li>
        
        
        
    </ul>
</div>

    <div class="autopagerize_page_element">
        <div class="content">

    <div class="post  . ">
    	
    	
    		<nav id="TableOfContents">
  <ul>
    <li><a href="#1-investigating-the-website">1. Investigating the website</a></li>
    <li><a href="#2-web-scraping-with-selenium">2. Web Scraping with Selenium</a></li>
    <li><a href="#3-putting-it-all-together">3. Putting it all together</a></li>
  </ul>
</nav>
        
    	
        <div class="post-content">
            
            <div class="post-title">
                <h2>The beautiful Game - Scraping xG and xGA from understat.com</h3>
                
                    <div class="info">
                        <em class="fas fa-calendar-day"></em>
                        <span class="date"> 
                                                Tue, Jan 5, 2021
                                           </span>
                        <em class="fas fa-stopwatch"></em>
                        <span class="reading-time">10-minute read</span>
                    </div>
                    <div>
                    	<hr style="height:1px;border-width:0;background-color:rgba(0,0,0,0.15)">
                    </div>
                
            </div>
            
            
	    <div class="post-content-text">
    	        <p>In recent years, soccer has increasingly become a multi-billion euro industry. In order identify drivers of success and to better analyze the matches, more and more (match) data is collected and new metrics are used to describe the teams&rsquo; performance. Two of such new metrics are the so called expected goals (xG) and expected goals against (xGA). xG try to quantify not only how many shots and chances a team had during a game, but also aims at quantifying the quality of these chances, considering from where the shot was taken, the angle to the goal and how many opponents were still between the ball and the goal. xGA are very similar to xG, but try to quantify the expected goals a team would concede. xG and xGA can also be seen as being the probability of a shot scoring a goal. Hence, xG/xGA are always between 0 and 1 for a single shot.</p>
<p>Since these metrics are fairly new, they are often not included in post match statistics. One of the few websites which report these is understat.com. In this project, I use python and the selenium package to click through the webpage and extract the reported post match data for all matches and leagues for which there are data given.</p>
<h2 id="1-investigating-the-website">1. Investigating the website</h2>
<p>The first step in each web scraping project is to take a look at the webpage and identify the steps needed to get to the desired data. <a href="https://understat.com/">understat</a> provides data for 6 major leagues: Premier League (<em>EPL</em>), La Liga (<em>La_liga</em>), Bundesliga (<em>Bundesliga</em>), Serie A (<em>Serie_A</em>), Ligue 1 (<em>Ligue_1</em>), and the Russian Premier League (<em>RFPL</em>). The landing page for the respective league can be accessed via:</p>
<blockquote>
<p><a href="https://understat.com/league/xxx">https://understat.com/league/xxx</a></p>
</blockquote>
<p>where <em>xxx</em> is the league&rsquo;s abbreviation given in parentheses above. The landing page shows the upcoming matches in the respective league. To explicitly choose a season it is possible to add the starting year of the season, e.g. to get to the results for the Bundesliga from the season 2018/2019, the link would be</p>
<blockquote>
<p><a href="https://understat.com/league/Bundesliga/2018">https://understat.com/league/Bundesliga/2018</a></p>
</blockquote>
<p>The first season, for which there is data is 2014/2015.</p>
<p>In the following I use the Bundesliga season of 2018/2019 as an example to further guide through the code and the data extraction process. When opening the <a href="https://understat.com/league/Bundesliga/2018">link to this season</a>, there are two buttons which can be used to navigate through the season, previous week and next week:</p>
<p><img src="landingpage.png" alt="landingpage.png"></p>
<p>However, when navigating through the season, the link does not change at all, and accessing the above stated URL always points to the landing page, i.e. the upcoming matches or the last matchday of the season. Hence, storing the links in a list, going through this list and extract the data using <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">beautifulsoup</a> for example, would not work. We need a solution which independently clicks through the page and extracts then extracts the relevant data.</p>
<h2 id="2-web-scraping-with-selenium">2. Web Scraping with Selenium</h2>
<p>Here is where <a href="https://selenium-python.readthedocs.io/index.html">Selenium</a> comes into play. The documentation states in the introduction:</p>
<blockquote>
<p>Selenium Python bindings provides a simple API to write functional/acceptance tests using Selenium WebDriver. Through Selenium Python API you can access all functionalities of Selenium WebDriver in an intuitive way. Selenium Python bindings provide a convenient API to access Selenium WebDrivers like Firefox, Ie, Chrome, Remote etc.</p>
</blockquote>
<p>In this project, we use Selenium in combination with the Chrome Webdriver to click through the pages and access the relevant information. We will run chrome in headless mode to avoid opening an actual browser window. A short function is written to initialize the browser:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">initialize_browser</span><span class="p">(</span><span class="n">headless</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    :param headless: bool, should chrome run in headless mode, i.e. in background
</span><span class="s2">    :return: browser object used for all other functions
</span><span class="s2">    &#34;&#34;&#34;</span>

    <span class="c1"># set chrome options</span>
    <span class="n">chrome_options</span> <span class="o">=</span> <span class="n">webdriver</span><span class="o">.</span><span class="n">ChromeOptions</span><span class="p">()</span>
    <span class="n">chrome_options</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&#34;--disable-gpu&#34;</span><span class="p">)</span>
    <span class="n">chrome_options</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&#34;--disable-extensions&#34;</span><span class="p">)</span>
    <span class="n">chrome_options</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&#34;--no-sandbox&#34;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">headless</span><span class="p">:</span>
        <span class="n">chrome_options</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&#34;--headless&#34;</span><span class="p">)</span>

    <span class="c1"># Initialize a new browser</span>
    <span class="n">browser</span> <span class="o">=</span> <span class="n">webdriver</span><span class="o">.</span><span class="n">Chrome</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="n">chrome_options</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">browser</span>

<span class="n">browser</span> <span class="o">=</span> <span class="n">initialize_browser</span><span class="p">()</span>
</code></pre></div><p>The next step is to point selenium to the buttons which are to be clicked on. To find the elements we are looking for, we open the webpage in chrome, right-click on the page, and select &ldquo;Inspect&rdquo;. In the window on the right we click on &ldquo;Select an element in the page to inspect it&rdquo; and click on the &ldquo;prev week&rdquo; and &ldquo;next week&rdquo; buttons. From the panel on the right we can see the classes of these buttons and use the &ldquo;find_element_by_class_name&rdquo; function to find them. This approach is used for all the elements we find to find throughout this project.</p>
<p><img src="prevButton.png" alt="prevButton.png"></p>
<p>We can then use the information we have until this point to access the landing page and click to the first week of the season with the following code:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">browser</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&#34;https://understat.com/league/bundesliga/2018&#34;</span><span class="p">)</span>
<span class="n">prev_week</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_class_name</span><span class="p">(</span><span class="s2">&#34;calendar-prev&#34;</span><span class="p">)</span>
<span class="k">while</span> <span class="n">prev_week</span><span class="o">.</span><span class="n">is_enabled</span><span class="p">():</span>
    <span class="n">prev_week</span><span class="o">.</span><span class="n">click</span><span class="p">()</span>
</code></pre></div><p>We now need to write the functionality to extract the relevant match data for all the matches for each week. We will let Selenium imitate the following workflow:</p>
<ol>
<li>click on a match</li>
<li>select the &ldquo;Stats&rdquo; tab</li>
<li>find the classes of all the stats listed and store them in variables</li>
</ol>
<p><img src="stats.png" alt="stats.png"></p>
<p>In addition to the class names, we also use XPaths to easily find the match data. This can be done in the same way as before using the &ldquo;Inspect&rdquo; tab. In order to extract the data and to keep the code readable, we define some helper functions, which edit the strings into the desired format:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">get_element</span><span class="p">(</span><span class="n">className</span><span class="p">,</span> <span class="n">browser</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    :param className: string - name of the class which is to be retrieved
</span><span class="s2">    :param browser: browser object, initialized by initialize_browser()
</span><span class="s2">    :return text of element as string
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="n">regex</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">&#34;[\n\r\t]&#34;</span><span class="p">)</span> <span class="c1"># compile regular expression</span>
    <span class="n">element</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_class_name</span><span class="p">(</span><span class="n">className</span><span class="p">)</span> <span class="c1"># find element</span>
    <span class="n">element</span> <span class="o">=</span> <span class="n">element</span><span class="o">.</span><span class="n">get_attribute</span><span class="p">(</span><span class="s2">&#34;innerText&#34;</span><span class="p">)</span> <span class="c1"># extract html</span>
    <span class="n">element</span> <span class="o">=</span> <span class="n">regex</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&#34;&#34;</span><span class="p">,</span> <span class="n">element</span><span class="p">)</span> <span class="c1"># remove unwanted parts of the string</span>
    <span class="k">return</span> <span class="n">element</span>


<span class="k">def</span> <span class="nf">get_element_xpath</span><span class="p">(</span><span class="n">xpath</span><span class="p">,</span> <span class="n">browser</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    :param xpath: string - xpath to the element which is to be retrieved
</span><span class="s2">    :param browser: browser object, initialized by initialize_browser()
</span><span class="s2">    :return: text of element as string
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="n">element</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_xpath</span><span class="p">(</span><span class="n">xpath</span><span class="p">)</span><span class="o">.</span><span class="n">get_attribute</span><span class="p">(</span><span class="s2">&#34;innerHTML&#34;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">element</span>


<span class="k">def</span> <span class="nf">get_float</span><span class="p">(</span><span class="n">xpath</span><span class="p">,</span> <span class="n">browser</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    :param xpath: string - xpath to the element which is to be retrieved
</span><span class="s2">    :param browser: browser object, initialized by initialize_browser()
</span><span class="s2">    :return: element as float object
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="n">element</span> <span class="o">=</span> <span class="n">get_element_xpath</span><span class="p">(</span><span class="n">xpath</span><span class="p">,</span> <span class="n">browser</span><span class="p">)</span>
    <span class="n">regex</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">&#34;&lt;[^&gt;]+&gt;&#34;</span><span class="p">)</span>
    <span class="n">element</span> <span class="o">=</span> <span class="n">regex</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&#34;&#34;</span><span class="p">,</span> <span class="n">element</span><span class="p">)</span>
    <span class="n">element</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">element</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">element</span>


<span class="k">def</span> <span class="nf">get_date</span><span class="p">(</span><span class="n">xpath</span><span class="p">,</span> <span class="n">browser</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    :param xpath: string - xpath to the date element
</span><span class="s2">    :param browser: browser object, initialized by initialize_browser()
</span><span class="s2">    :return: date as datetime object
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="n">element</span> <span class="o">=</span> <span class="n">get_element_xpath</span><span class="p">(</span><span class="n">xpath</span><span class="p">,</span> <span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">)</span>
    <span class="n">element</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">strptime</span><span class="p">(</span><span class="n">element</span><span class="p">,</span> <span class="s2">&#34;%b </span><span class="si">%d</span><span class="s2"> %Y&#34;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">element</span>
</code></pre></div><p>The first function extracts contents from an element using its class name, the second does the same, but using the XPath as input, the third one converts the data into a float, and the last one extracts the date as a special date object. Building on these functions we define another function, which extracts all the data for a single match and returns it as a dictionary:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">scrape_match_infos</span><span class="p">(</span><span class="n">browser</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    :param browser: browser object, initialized by initialize_browser()
</span><span class="s2">    :return: all date for a single match from its corresponding page as a dictionary
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="n">matchData</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&#34;date&#34;</span> <span class="p">:</span> <span class="n">get_date</span><span class="p">(</span><span class="s2">&#34;/html/body/div[1]/div[3]/ul/li[3]&#34;</span><span class="p">,</span> <span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">),</span>
        <span class="s2">&#34;homeTeam&#34;</span> <span class="p">:</span> <span class="n">get_element</span><span class="p">(</span><span class="s2">&#34;progress-home.progress-over&#34;</span><span class="p">,</span> <span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">),</span>
        <span class="s2">&#34;awayTeam&#34;</span> <span class="p">:</span> <span class="n">get_element</span><span class="p">(</span><span class="s2">&#34;progress-away&#34;</span><span class="p">,</span> <span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">),</span>
        <span class="s2">&#34;homeGoals&#34;</span> <span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">get_element_xpath</span><span class="p">(</span><span class="s2">&#34;/html/body/div[1]/div[3]/div[2]/div[1]/div/div[4]/div[3]/div[2]/div&#34;</span><span class="p">,</span> <span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">)),</span>
        <span class="s2">&#34;awayGoals&#34;</span> <span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">get_element_xpath</span><span class="p">(</span><span class="s2">&#34;/html/body/div[1]/div[3]/div[2]/div[1]/div/div[4]/div[3]/div[3]/div&#34;</span><span class="p">,</span> <span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">)),</span>
        <span class="s2">&#34;xgHome&#34;</span> <span class="p">:</span> <span class="n">get_float</span><span class="p">(</span><span class="s2">&#34;/html/body/div[1]/div[3]/div[2]/div[1]/div/div[4]/div[4]/div[2]/div&#34;</span><span class="p">,</span> <span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">),</span>
        <span class="s2">&#34;xgAway&#34;</span> <span class="p">:</span> <span class="n">get_float</span><span class="p">(</span><span class="s2">&#34;/html/body/div[1]/div[3]/div[2]/div[1]/div/div[4]/div[4]/div[3]/div&#34;</span><span class="p">,</span> <span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">),</span>
        <span class="s2">&#34;shotsHome&#34;</span> <span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">get_element_xpath</span><span class="p">(</span><span class="s2">&#34;/html/body/div[1]/div[3]/div[2]/div[1]/div/div[4]/div[5]/div[2]/div&#34;</span><span class="p">,</span> <span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">)),</span>
        <span class="s2">&#34;shotsAway&#34;</span> <span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">get_element_xpath</span><span class="p">(</span><span class="s2">&#34;/html/body/div[1]/div[3]/div[2]/div[1]/div/div[4]/div[5]/div[3]/div&#34;</span><span class="p">,</span> <span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">)),</span>
        <span class="s2">&#34;shotsOnTargetHome&#34;</span> <span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">get_element_xpath</span><span class="p">(</span><span class="s2">&#34;/html/body/div[1]/div[3]/div[2]/div[1]/div/div[4]/div[6]/div[2]/div&#34;</span><span class="p">,</span> <span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">)),</span>
        <span class="s2">&#34;shotsOnTargetAway&#34;</span> <span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">get_element_xpath</span><span class="p">(</span><span class="s2">&#34;/html/body/div[1]/div[3]/div[2]/div[1]/div/div[4]/div[6]/div[3]/div&#34;</span><span class="p">,</span> <span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">)),</span>
        <span class="s2">&#34;deepHome&#34;</span> <span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">get_element_xpath</span><span class="p">(</span><span class="s2">&#34;/html/body/div[1]/div[3]/div[2]/div[1]/div/div[4]/div[7]/div[2]/div&#34;</span><span class="p">,</span> <span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">)),</span>
        <span class="s2">&#34;deepAway&#34;</span> <span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">get_element_xpath</span><span class="p">(</span><span class="s2">&#34;/html/body/div[1]/div[3]/div[2]/div[1]/div/div[4]/div[7]/div[3]/div&#34;</span><span class="p">,</span> <span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">)),</span>
        <span class="s2">&#34;ppdaHome&#34;</span> <span class="p">:</span> <span class="n">get_float</span><span class="p">(</span><span class="s2">&#34;/html/body/div[1]/div[3]/div[2]/div[1]/div/div[4]/div[8]/div[2]/div&#34;</span><span class="p">,</span> <span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">),</span>
        <span class="s2">&#34;ppdaAway&#34;</span> <span class="p">:</span> <span class="n">get_float</span><span class="p">(</span><span class="s2">&#34;/html/body/div[1]/div[3]/div[2]/div[1]/div/div[4]/div[8]/div[3]/div&#34;</span><span class="p">,</span> <span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">),</span>
        <span class="s2">&#34;xptsHome&#34;</span> <span class="p">:</span> <span class="n">get_float</span><span class="p">(</span><span class="s2">&#34;/html/body/div[1]/div[3]/div[2]/div[1]/div/div[4]/div[9]/div[2]/div&#34;</span><span class="p">,</span> <span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">),</span>
        <span class="s2">&#34;xptsAway&#34;</span> <span class="p">:</span> <span class="n">get_float</span><span class="p">(</span><span class="s2">&#34;/html/body/div[1]/div[3]/div[2]/div[1]/div/div[4]/div[9]/div[3]/div&#34;</span><span class="p">,</span> <span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">)</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">matchData</span>
</code></pre></div><p>We want the script to do this for all the matches found on a week&rsquo;s landing page. However, when clicking on a match and then returning to the overview for the week by clicking the browser&rsquo;s &ldquo;back&rdquo; button, understat displays the current or last week of a season again. Therefore, after navigating to the desired week overview page, the elements to all the matches are found and the corresponding links are extracted and stored in a list. In a second step, the code iterates over this list of links to the matches, opens the links and extracts the match infos. The information is then stored in a list of dictionaries and returned by the function.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">scrape_page</span><span class="p">(</span><span class="n">browser</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    :param browser: browser object, initialized by initialize_browser()
</span><span class="s2">    :return: data for all matches from a &#34;week overview&#34; page
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="c1"># initialize empty list for match data and links</span>
    <span class="n">dicts</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">links</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># get all matches from a page and save links</span>
    <span class="n">matches</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_elements_by_class_name</span><span class="p">(</span><span class="s2">&#34;match-info&#34;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">matches</span><span class="p">)):</span>
        <span class="n">links</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">matches</span><span class="p">[</span><span class="n">m</span><span class="p">]</span><span class="o">.</span><span class="n">get_attribute</span><span class="p">(</span><span class="s2">&#34;href&#34;</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">links</span><span class="p">:</span>
        <span class="n">browser</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">link</span><span class="p">)</span>
        <span class="n">matchInfos</span> <span class="o">=</span> <span class="n">scrape_match_infos</span><span class="p">(</span><span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">)</span>
        <span class="n">dicts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">matchInfos</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dicts</span>
</code></pre></div><p>Since we are now able to get all the data for one week, we want to apply this function to every week of the season. The &ldquo;scrape_season&rdquo; function defined below does exactly that. As an auxiliary step, the number of weeks in a season is counted by clicking through the whole season. The first week of a season is then accessed by clicking on the &ldquo;prev week&rdquo; button as many as times as there are weeks in the season, and all the match data for this week is extracted using the &ldquo;scrape_page&rdquo; function. After this step, the weeks counter is decreased by one, such that during the next iteration, the data for the second week of the season is extracted, and so on. This is done until the last week of a season is reached. All the gathered information is then combined into a single list and converted into a pandas DataFrame.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">scrape_season</span><span class="p">(</span><span class="n">league</span><span class="p">,</span> <span class="n">season</span><span class="p">,</span> <span class="n">browser</span><span class="p">):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    :param league: string - name of the league for which data is to be retrieved;
</span><span class="s2">                   one out of [&#34;EPL&#34;, &#34;La_liga&#34;, &#34;Bundesliga&#34;, &#34;Serie_A&#34;, 
</span><span class="s2">                               &#34;Ligue_1&#34;, &#34;RFPL&#34;]
</span><span class="s2">    :param season: list - seasons for which data should be collected
</span><span class="s2">                    possible values: [2014, 2015, 2016, 2017, 2018, 2019]
</span><span class="s2">    :param browser: browser object, initialized by initialize_browser()
</span><span class="s2">    :return:
</span><span class="s2">    &#34;&#34;&#34;</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;Getting data for {}: Season {}.&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">league</span><span class="p">,</span> <span class="n">season</span><span class="p">))</span>

    <span class="c1"># initialize empty list for data storage</span>
    <span class="n">allMatches</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># define url</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s2">&#34;https://understat.com/league/&#34;</span> <span class="o">+</span> <span class="n">league</span> <span class="o">+</span> <span class="s2">&#34;/&#34;</span> <span class="o">+</span> <span class="n">season</span>

    <span class="c1"># open landing page</span>
    <span class="n">browser</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

    <span class="c1"># find button for previous week and next week</span>
    <span class="n">prev_week</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_class_name</span><span class="p">(</span><span class="s2">&#34;calendar-prev&#34;</span><span class="p">)</span>

    <span class="c1"># go to the first week and store the number of pages per season</span>
    <span class="n">numOfPages</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">while</span> <span class="n">prev_week</span><span class="o">.</span><span class="n">is_enabled</span><span class="p">():</span>
        <span class="n">numOfPages</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">prev_week</span><span class="o">.</span><span class="n">click</span><span class="p">()</span>

    <span class="c1"># scrape all the pages</span>
    <span class="k">while</span> <span class="n">numOfPages</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">browser</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
        <span class="n">prev_week</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_class_name</span><span class="p">(</span><span class="s2">&#34;calendar-prev&#34;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">numOfPages</span><span class="p">):</span>
            <span class="n">prev_week</span><span class="o">.</span><span class="n">click</span><span class="p">()</span>
        <span class="n">matchday</span> <span class="o">=</span> <span class="n">scrape_page</span><span class="p">(</span><span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">)</span>
        <span class="n">allMatches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">matchday</span><span class="p">)</span>
        <span class="n">numOfPages</span> <span class="o">-=</span> <span class="mi">1</span>

    <span class="n">allMatches</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">(</span><span class="n">allMatches</span><span class="p">))</span>
    <span class="n">allMatches</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">allMatches</span><span class="p">)</span>
    <span class="n">allMatches</span><span class="p">[</span><span class="s2">&#34;season&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">season</span>
    <span class="n">allMatches</span><span class="p">[</span><span class="s2">&#34;league&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">league</span>
    <span class="k">return</span> <span class="n">allMatches</span>
</code></pre></div><h2 id="3-putting-it-all-together">3. Putting it all together</h2>
<p>We now have all the functionality we need to scrape a whole season. The only thing left now is a simple wrapper function, which can be used to scrape multiple seasons of a league. This function takes a league, a browser object and a list of seasons as inputs, iterates through all the seasons in the list and scrapes each of those. The data is then combined into a single DataFrame and returned.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">scrape_league</span><span class="p">(</span><span class="n">league</span><span class="p">,</span> <span class="n">browser</span><span class="p">,</span> <span class="n">seasons</span><span class="o">=</span><span class="p">[</span><span class="mi">2014</span><span class="p">,</span> <span class="mi">2015</span><span class="p">,</span> <span class="mi">2016</span><span class="p">,</span> <span class="mi">2017</span><span class="p">,</span> <span class="mi">2018</span><span class="p">,</span> <span class="mi">2019</span><span class="p">]):</span>
    <span class="s2">&#34;&#34;&#34;
</span><span class="s2">    :param league: string - name of the league for which data is to be retrieved;
</span><span class="s2">                   one out of [&#34;EPL&#34;, &#34;La_liga&#34;, &#34;Bundesliga&#34;, &#34;Serie_A&#34;, 
</span><span class="s2">                               &#34;Ligue_1&#34;, &#34;RFPL&#34;]
</span><span class="s2">    :param browser: browser object, initialized by initialize_browser()
</span><span class="s2">    :param seasons: list - seasons for which data should be collected
</span><span class="s2">                    possible values: [2014, 2015, 2016, 2017, 2018, 2019]
</span><span class="s2">    :return:
</span><span class="s2">    &#34;&#34;&#34;</span>

    <span class="c1"># convert elements in season list to string</span>
    <span class="n">seasons</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">season</span><span class="p">)</span> <span class="k">for</span> <span class="n">season</span> <span class="ow">in</span> <span class="n">seasons</span><span class="p">]</span>

    <span class="n">leagueData</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">season</span> <span class="ow">in</span> <span class="n">seasons</span><span class="p">:</span>
        <span class="n">seasonDat</span> <span class="o">=</span> <span class="n">scrape_season</span><span class="p">(</span><span class="n">league</span><span class="o">=</span><span class="n">league</span><span class="p">,</span> <span class="n">season</span><span class="o">=</span><span class="n">season</span><span class="p">,</span> <span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">)</span>
        <span class="n">leagueData</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">seasonDat</span><span class="p">)</span>

    <span class="c1"># combine dataframes to single dataframe</span>
    <span class="n">leagueDF</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">leagueData</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">leagueDF</span>
</code></pre></div><p>Combining all the steps described above, all the data for the Bundesliga from season 2014/2015 up to 2019/2020 can be retreived with the following lines of code (note that this may take some time):</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">browser</span> <span class="o">=</span> <span class="n">initialize_browser</span><span class="p">()</span> <span class="c1"># initialize the browser object</span>
<span class="n">bundesligaData</span> <span class="o">=</span> <span class="n">scrape_league</span><span class="p">(</span><span class="s2">&#34;Bundesliga&#34;</span><span class="p">,</span> <span class="n">browser</span><span class="o">=</span><span class="n">browser</span><span class="p">)</span>
</code></pre></div><pre><code>Getting data for Bundesliga: Season 2014.
Getting data for Bundesliga: Season 2015.
Getting data for Bundesliga: Season 2016.
Getting data for Bundesliga: Season 2017.
Getting data for Bundesliga: Season 2018.
Getting data for Bundesliga: Season 2019.
</code></pre>
<p>The data can then be saved, e.g. as a CSV file:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">bundesligaData</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&#34;bundesliga.csv&#34;</span><span class="p">)</span>
</code></pre></div><p>Or into a .db file using <a href="https://www.sqlite.org/index.html">sqlite</a>:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">con</span> <span class="o">=</span> <span class="n">sqlite3</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="s2">&#34;./soccerData.db&#34;</span><span class="p">)</span> <span class="c1"># create / connect to DB file</span>
<span class="n">bundesligaData</span><span class="o">.</span><span class="n">to_sql</span><span class="p">(</span><span class="s2">&#34;soccerData.db&#34;</span><span class="p">,</span> <span class="n">con</span><span class="p">)</span> <span class="c1"># save data to DB</span>
</code></pre></div>
            </div></div>
        
        

        
    </div>
    


        </div>
    </div>
</div>

<script type="text/javascript"
        src="../../js/jquery.min.86b1e8f819ee2d9099a783e50b49dff24282545fc40773861f9126b921532e4c.js"
        integrity="sha256-hrHo&#43;BnuLZCZp4PlC0nf8kKCVF/EB3OGH5EmuSFTLkw="
        crossorigin="anonymous"></script>




<script type="text/javascript"
        src="../../js/bundle.min.0f9c74cb78f13d1f15f33daff4037c70354f98acfbb97a6f61708966675c3cae.js"
        integrity="sha256-D5x0y3jxPR8V8z2v9AN8cDVPmKz7uXpvYXCJZmdcPK4="
        crossorigin="anonymous"></script>

<script type="text/javascript"
        src="../../js/medium-zoom.min.92f21c856129f84aeb719459b3e6ac621a3032fd7b180a18c04e1d12083f8aba.js"
        integrity="sha256-kvIchWEp&#43;ErrcZRZs&#43;asYhowMv17GAoYwE4dEgg/iro="
        crossorigin="anonymous"></script>
<link rel="stylesheet"
              href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
              integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/&#43;DiW/UqRcLbRjq"
              crossorigin="anonymous"><script defer
                src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
                integrity="sha384-y23I5Q6l&#43;B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd&#43;qj&#43;o24G5ZU2zJz"
                crossorigin="anonymous"></script><script defer
                src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
                integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI"
                crossorigin="anonymous"
                onload="renderMathInElement(document.body);"></script></body>

</html>